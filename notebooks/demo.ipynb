{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demo-title",
   "metadata": {},
   "source": [
    "# Parallel Requests Demo\n",
    "\n",
    "This notebook demonstrates making parallel POST requests to the HuggingFace Audio Classification API container endpoint.\n",
    "\n",
    "**Model**: MIT/ast-finetuned-audioset-10-10-0.4593 (Audio Spectrogram Transformer)\n",
    "\n",
    "**Endpoint**: http://localhost/api/v1/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ac59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "# API Configuration\n",
    "API_URL = 'http://localhost/api/v1/inference'\n",
    "HEALTH_URL = 'http://localhost/api/v1/health'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "health-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API is healthy and ready\n"
     ]
    }
   ],
   "source": [
    "# Check if API is running\n",
    "try:\n",
    "    response = requests.get(HEALTH_URL, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… API is healthy and ready\")\n",
    "        api_ready = True\n",
    "    else:\n",
    "        print(f\"âš ï¸ API returned status: {response.status_code}\")\n",
    "        api_ready = False\n",
    "except Exception as e:\n",
    "    print(f\"âŒ API not available: {e}\")\n",
    "    print(\"Make sure to run: docker compose up -d\")\n",
    "    api_ready = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generate-audio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 test audio files:\n",
      "  ğŸ“ music_sample.wav\n",
      "  ğŸ“ speech_sample.wav\n",
      "  ğŸ“ noise_sample.wav\n"
     ]
    }
   ],
   "source": [
    "# Generate test audio files\n",
    "def create_test_audio(filename: str, audio_type: str = \"music\"):\n",
    "    \"\"\"Create a simple test audio file\"\"\"\n",
    "    duration = 3  # 3 seconds\n",
    "    sample_rate = 16000  # AST model expects 16kHz\n",
    "    t = np.linspace(0, duration, duration * sample_rate)\n",
    "    \n",
    "    if audio_type == \"music\":\n",
    "        # Musical chord (C major)\n",
    "        audio = (np.sin(2 * np.pi * 261.63 * t) +  # C4\n",
    "                0.5 * np.sin(2 * np.pi * 329.63 * t) +  # E4  \n",
    "                0.3 * np.sin(2 * np.pi * 392.00 * t))   # G4\n",
    "    elif audio_type == \"speech\":\n",
    "        # Speech-like formants\n",
    "        audio = np.sin(2 * np.pi * 200 * t) * np.sin(2 * np.pi * 5 * t)\n",
    "    else:  # noise\n",
    "        # Filtered noise\n",
    "        audio = np.random.randn(len(t)) * 0.1\n",
    "    \n",
    "    # Normalize\n",
    "    audio = audio / np.max(np.abs(audio)) * 0.7\n",
    "    sf.write(filename, audio, sample_rate)\n",
    "    return filename\n",
    "\n",
    "# Create test files\n",
    "test_files = [\n",
    "    create_test_audio(\"music_sample.wav\", \"music\"),\n",
    "    create_test_audio(\"speech_sample.wav\", \"speech\"), \n",
    "    create_test_audio(\"noise_sample.wav\", \"noise\")\n",
    "]\n",
    "\n",
    "print(f\"Created {len(test_files)} test audio files:\")\n",
    "for f in test_files:\n",
    "    print(f\"  ğŸ“ {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "single-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Testing single request...\n",
      "\n",
      "ğŸ“Š Response for music_sample.wav:\n",
      "  1. Sine wave: 0.775\n",
      "  2. Dial tone: 0.147\n",
      "  3. Busy signal: 0.012\n",
      "\n",
      "Request took: 3.24s\n"
     ]
    }
   ],
   "source": [
    "# Single request example\n",
    "def send_single_request(audio_file: str) -> Dict:\n",
    "    \"\"\"Send a single POST request to the inference endpoint\"\"\"\n",
    "    with open(audio_file, 'rb') as f:\n",
    "        files = {'file': (audio_file, f, 'audio/wav')}\n",
    "        start_time = time.time()\n",
    "        response = requests.post(API_URL, files=files)\n",
    "        end_time = time.time()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        result['request_time'] = end_time - start_time\n",
    "        return result\n",
    "    else:\n",
    "        return {'error': f\"HTTP {response.status_code}: {response.text}\"}\n",
    "\n",
    "# Test single request\n",
    "if api_ready:\n",
    "    print(\"ğŸ¯ Testing single request...\")\n",
    "    result = send_single_request(test_files[0])\n",
    "    \n",
    "    if 'error' not in result:\n",
    "        print(f\"\\nğŸ“Š Response for {result['filename']}:\")\n",
    "        predictions = result['results']['predictions'][:3]  # Top 3\n",
    "        \n",
    "        for i, pred in enumerate(predictions):\n",
    "            print(f\"  {i+1}. {pred['label']}: {pred['score']:.3f}\")\n",
    "        \n",
    "        print(f\"\\nRequest took: {result['request_time']:.2f}s\")\n",
    "    else:\n",
    "        print(f\"âŒ Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parallel-requests",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel requests implementation\n",
    "async def send_async_request(session: aiohttp.ClientSession, audio_file: str) -> Dict:\n",
    "    \"\"\"Send an async POST request\"\"\"\n",
    "    try:\n",
    "        with open(audio_file, 'rb') as f:\n",
    "            data = aiohttp.FormData()\n",
    "            data.add_field('file', f, filename=audio_file, content_type='audio/wav')\n",
    "            \n",
    "            start_time = time.time()\n",
    "            async with session.post(API_URL, data=data) as response:\n",
    "                end_time = time.time()\n",
    "                \n",
    "                if response.status == 200:\n",
    "                    result = await response.json()\n",
    "                    result['request_time'] = end_time - start_time\n",
    "                    result['audio_file'] = audio_file\n",
    "                    return result\n",
    "                else:\n",
    "                    text = await response.text()\n",
    "                    return {\n",
    "                        'error': f\"HTTP {response.status}: {text}\",\n",
    "                        'audio_file': audio_file,\n",
    "                        'request_time': end_time - start_time\n",
    "                    }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'error': str(e),\n",
    "            'audio_file': audio_file,\n",
    "            'request_time': 0\n",
    "        }\n",
    "\n",
    "async def send_parallel_requests(audio_files: List[str]) -> List[Dict]:\n",
    "    \"\"\"Send multiple requests in parallel\"\"\"\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [send_async_request(session, file) for file in audio_files]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demo-parallel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Sending parallel requests to all test files...\n",
      "\n",
      "ğŸ“Š Parallel Results (completed in 5.60s):\n",
      "============================================================\n",
      "\n",
      "ğŸ“ File: music_sample.wav\n",
      "â±ï¸  Request time: 5.59s\n",
      "ğŸ† Top prediction: Sine wave (0.775)\n",
      "ğŸ“ˆ Top 3:\n",
      "   1. Sine wave: 0.775\n",
      "   2. Dial tone: 0.147\n",
      "   3. Busy signal: 0.012\n",
      "\n",
      "ğŸ“ File: speech_sample.wav\n",
      "â±ï¸  Request time: 5.30s\n",
      "ğŸ† Top prediction: Sine wave (0.716)\n",
      "ğŸ“ˆ Top 3:\n",
      "   1. Sine wave: 0.716\n",
      "   2. Sound effect: 0.054\n",
      "   3. Busy signal: 0.034\n",
      "\n",
      "ğŸ“ File: noise_sample.wav\n",
      "â±ï¸  Request time: 5.47s\n",
      "ğŸ† Top prediction: Static (0.798)\n",
      "ğŸ“ˆ Top 3:\n",
      "   1. Static: 0.798\n",
      "   2. White noise: 0.093\n",
      "   3. Speech: 0.015\n",
      "\n",
      "============================================================\n",
      "âœ… Successful requests: 3/3\n",
      "âš¡ Average response time: 5.45s\n",
      "ğŸš€ Total time for parallel requests: 5.60s\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate parallel requests\n",
    "if api_ready:\n",
    "    print(\"âš¡ Sending parallel requests to all test files...\\n\")\n",
    "    \n",
    "    # Send requests in parallel\n",
    "    start_time = time.time()\n",
    "    results = await send_parallel_requests(test_files)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"ğŸ“Š Parallel Results (completed in {total_time:.2f}s):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if 'error' not in result:\n",
    "            print(f\"\\nğŸ“ File: {result['audio_file']}\")\n",
    "            print(f\"â±ï¸  Request time: {result['request_time']:.2f}s\")\n",
    "            \n",
    "            # Get top prediction\n",
    "            predictions = result['results']['predictions']\n",
    "            top_pred = max(predictions, key=lambda x: x['score'])\n",
    "            print(f\"ğŸ† Top prediction: {top_pred['label']} ({top_pred['score']:.3f})\")\n",
    "            \n",
    "            # Show top 3\n",
    "            sorted_preds = sorted(predictions, key=lambda x: x['score'], reverse=True)[:3]\n",
    "            print(\"ğŸ“ˆ Top 3:\")\n",
    "            for j, pred in enumerate(sorted_preds):\n",
    "                print(f\"   {j+1}. {pred['label']}: {pred['score']:.3f}\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ Error for {result['audio_file']}: {result['error']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    successful_requests = sum(1 for r in results if 'error' not in r)\n",
    "    avg_response_time = np.mean([r['request_time'] for r in results if 'request_time' in r])\n",
    "    \n",
    "    print(f\"âœ… Successful requests: {successful_requests}/{len(results)}\")\n",
    "    print(f\"âš¡ Average response time: {avg_response_time:.2f}s\")\n",
    "    print(f\"ğŸš€ Total time for parallel requests: {total_time:.2f}s\")\n",
    "else:\n",
    "    print(\"âŒ API not ready. Please start the containers first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stress-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Running a simple stress test (10 concurrent requests)...\n",
      "\n",
      "ğŸ“Š Stress Test Results:\n",
      "   Total requests: 12\n",
      "   âœ… Successful: 12\n",
      "   âŒ Failed: 0\n",
      "   âš¡ Total time: 28.46s\n",
      "   ğŸš€ Requests/second: 0.4\n",
      "   ğŸ“ˆ Avg response time: 27.99s\n",
      "   ğŸ“Š Max response time: 28.45s\n"
     ]
    }
   ],
   "source": [
    "# Optional: Simple stress test\n",
    "if api_ready:\n",
    "    print(\"ğŸ”¥ Running a simple stress test (10 concurrent requests)...\\n\")\n",
    "    \n",
    "    # Create multiple requests using the same files\n",
    "    stress_files = test_files * 4  # 12 total requests (3 files Ã— 4)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    stress_results = await send_parallel_requests(stress_files)\n",
    "    stress_time = time.time() - start_time\n",
    "    \n",
    "    successful = sum(1 for r in stress_results if 'error' not in r)\n",
    "    failed = len(stress_results) - successful\n",
    "    \n",
    "    print(f\"ğŸ“Š Stress Test Results:\")\n",
    "    print(f\"   Total requests: {len(stress_results)}\")\n",
    "    print(f\"   âœ… Successful: {successful}\")\n",
    "    print(f\"   âŒ Failed: {failed}\")\n",
    "    print(f\"   âš¡ Total time: {stress_time:.2f}s\")\n",
    "    print(f\"   ğŸš€ Requests/second: {len(stress_results)/stress_time:.1f}\")\n",
    "    \n",
    "    if successful > 0:\n",
    "        response_times = [r['request_time'] for r in stress_results if 'request_time' in r and r['request_time'] > 0]\n",
    "        print(f\"   ğŸ“ˆ Avg response time: {np.mean(response_times):.2f}s\")\n",
    "        print(f\"   ğŸ“Š Max response time: {max(response_times):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **âœ… Health Check**: Verified the API container is running\n",
    "2. **ğŸ“ Test Data**: Generated synthetic audio files for testing\n",
    "3. **ğŸ¯ Single Request**: Made a single POST request to the inference endpoint\n",
    "4. **âš¡ Parallel Requests**: Used `asyncio` and `aiohttp` to send multiple requests concurrently\n",
    "5. **ğŸ“Š Response Analysis**: Printed and analyzed the API responses\n",
    "6. **ğŸ”¥ Stress Testing**: Tested the API with multiple concurrent requests\n",
    "\n",
    "**Key Benefits of Parallel Requests:**\n",
    "- Much faster than sequential requests\n",
    "- Better utilization of the API server\n",
    "- Demonstrates the scalability of the containerized solution\n",
    "\n",
    "**To run this demo:**\n",
    "1. Start the containers: `docker compose up -d`\n",
    "2. Wait for the model to load (~2-3 minutes)\n",
    "3. Run this notebook\n",
    "\n",
    "The API uses the **Audio Spectrogram Transformer (AST)** model trained on AudioSet, which can classify 527 different types of audio events including music, speech, environmental sounds, and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
